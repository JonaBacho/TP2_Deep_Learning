# ğŸ§  MNIST MLOps : Pipeline de Deep Learning End-to-End

[![MLflow](https://img.shields.io/badge/MLflow-2.10.2-blue.svg)](https://mlflow.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://tensorflow.org/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

Ce projet implÃ©mente un pipeline MLOps complet pour la classification de chiffres manuscrits (MNIST). Il couvre l'entraÃ®nement, le suivi des expÃ©riences, le registre de modÃ¨les avec **MLflow**, le dÃ©ploiement via **Flask** dans un conteneur **Docker**, et l'automatisation **CI/CD** avec GitHub Actions.

## ğŸš€ FonctionnalitÃ©s ClÃ©s

*   **EntraÃ®nement AutomatisÃ©** : Script d'entraÃ®nement avec gestion des hyperparamÃ¨tres et export vers MLflow.
*   **Tracking & Registry** : Suivi des mÃ©triques (Accuracy, F1-Score) et gestion des versions de modÃ¨les avec MLflow.
*   **Promotion Intelligente** : Logique de promotion automatique du modÃ¨le en "Production" basÃ©e sur des seuils de performance (Accuracy > 95% par dÃ©faut).
*   **API REST** : Service de prÃ©diction performant utilisant Flask et Gunicorn.
*   **Conteneurisation** : Image Docker optimisÃ©e basÃ©e sur Python Slim pour le dÃ©ploiement en production.
*   **CI/CD robuste** : 
    *   **Workflow d'EntraÃ®nement** : EntraÃ®ne, enregistre et auto-promeut les modÃ¨les.
    *   **Workflow de DÃ©ploiement** : Build Docker, test de santÃ© et dÃ©ploiement automatique sur serveur distant via SSH.

---

## ğŸ“ Structure du Projet

```text
â”œâ”€â”€ config/                 # Configuration centralisÃ©e (MLflow, S3/MinIO)
â”œâ”€â”€ src/                    # Code source principal
â”‚   â”œâ”€â”€ app.py              # API Flask (Service de prÃ©diction)
â”‚   â”œâ”€â”€ train_model.py      # Script d'entraÃ®nement et logging MLflow
â”‚   â”œâ”€â”€ auto_promote.py     # Logique de promotion basÃ©e sur les seuils
â”‚   â””â”€â”€ promote_model.py    # Utilitaire de gestion manuelle des stages
â”œâ”€â”€ tests/                  # Tests unitaires (API, chargement modÃ¨le)
â”œâ”€â”€ .github/workflows/      # Pipelines CI/CD (GitHub Actions)
â”œâ”€â”€ Dockerfile              # Configuration de l'image de production
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â””â”€â”€ .env.example            # Template des variables d'environnement
```

## ğŸ› ï¸ Configuration et Installation
1. PrÃ©requis
 - Python 3.10+

 - Docker & Docker Compose

 - Un accÃ¨s Ã  un serveur MLflow (distant ou local)

2. Installation locale

```Bash
# Cloner le projet
git clone <votre-repo-url>
cd TP1_Deep_Learning

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt
```

3. Variables d'environnement
Copiez le fichier .env.example en .env et remplissez vos accÃ¨s :

```Bash
cp .env.example .env
Assurez-vous de bien configurer MLFLOW_TRACKING_URI et les accÃ¨s S3 pour les artefacts.
```

## ğŸ”Œ Utilisation
EntraÃ®nement d'un modÃ¨le
Lancement de l'entraÃ®nement avec enregistrement automatique dans MLflow :


```Bash
python -m src.train_model
Lancement de l'API (DÃ©veloppement)
```

```Bash
python -m src.app
L'API sera accessible sur http://localhost:5000.
```

DÃ©ploiement avec Docker
```Bash
# Build de l'image
docker build -t mnist-mlflow-app .

# Lancement du conteneur
docker run -p 5000:5000 --env-file .env mnist-mlflow-app
```

## ğŸ›£ï¸ API Endpoints
MÃ©thode	Endpoint	Description
GET	/health	Ã‰tat de santÃ© et version du modÃ¨le chargÃ©.
GET	/model/info	Informations dÃ©taillÃ©es sur le modÃ¨le en production.
POST	/predict	PrÃ©dit un chiffre Ã  partir d'un array JSON (784 pixels).
POST	/model/reload	Force le rechargement du modÃ¨le depuis MLflow.
Exemple de requÃªte /predict :


```JSON
{
  "image": [0, 0, 0.5, 0.8, ..., 0] 
}
```

## ğŸ¤– Pipeline CI/CD
Le projet utilise deux workflows principaux :

1. MLflow Train and Register (train_register.yml) :

 - S'exÃ©cute sur push ou workflow_dispatch.

 - EntraÃ®ne le modÃ¨le avec TensorFlow.

 - Compare les performances avec le modÃ¨le actuel en Production.

 - Promeut le modÃ¨le si les critÃ¨res (MIN_ACCURACY) sont dÃ©passÃ©s.

2. Deploy Application (deploy.yml) :

 - Build l'image Docker et la pousse sur GHCR (GitHub Container Registry).

 - DÃ©ploie automatiquement sur le serveur de production via SSH.

 - VÃ©rifie la santÃ© du dÃ©ploiement (/health) aprÃ¨s le redÃ©marrage.

## ğŸ§ª Tests
Les tests sont automatisÃ©s et vÃ©rifient l'API ainsi que la robustesse du chargement de modÃ¨le :

```Bash
pytest tests/test_model.py
```

## âš–ï¸ Licence
DistribuÃ© sous la licence MIT. Voir LICENSE pour plus d'informations.