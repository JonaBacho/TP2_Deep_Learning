# üß† TP2: Improving Deep Neural Networks - MLOps Pipeline

[![TP2 Experiments](https://github.com/<YOUR-USERNAME>/<YOUR-REPO>/actions/workflows/tp2-train-experiments.yml/badge.svg)](https://github.com/<YOUR-USERNAME>/<YOUR-REPO>/actions/workflows/tp2-train-experiments.yml)
[![MLflow](https://img.shields.io/badge/MLflow-2.9.2-blue.svg)](https://mlflow.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15-orange.svg)](https://tensorflow.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

**√âcole Nationale Sup√©rieure Polytechnique de Yaound√©**  
D√©partement de G√©nie Informatique - 5GI  
Instructeurs: Louis Fippo Fitime, Claude Tinku, Kerolle Sonfack

Ce projet impl√©mente le **TP2 sur l'am√©lioration des r√©seaux de neurones profonds** avec un pipeline MLOps complet. Il couvre le diagnostic bias/variance, la r√©gularisation, la batch normalization, la comparaison d'optimiseurs, le tracking MLflow et l'automatisation CI/CD via GitHub Actions.

---

## üéØ Objectifs d'Apprentissage

- **Diagnostiquer** les probl√®mes de high bias (underfitting) et high variance (overfitting)
- **Ma√Ætriser** les techniques de r√©gularisation : L2 et Dropout
- **Utiliser** la Batch Normalization pour stabiliser et acc√©l√©rer l'entra√Ænement
- **Comparer** les algorithmes d'optimisation : SGD with Momentum, RMSprop, Adam
- **Automatiser** l'entra√Ænement et le tracking via GitHub Actions et MLflow

---

## üìÅ Structure du Projet

```text
‚îú‚îÄ‚îÄ config/                          # Configuration centralis√©e
‚îÇ   ‚îî‚îÄ‚îÄ mlflow_config.py             # Configuration MLflow, S3/MinIO
‚îú‚îÄ‚îÄ src/                             # Code source principal
‚îÇ   ‚îú‚îÄ‚îÄ app.py                       # API Flask (Service de pr√©diction)
‚îÇ   ‚îú‚îÄ‚îÄ train_model.py               # TP1 - Entra√Ænement baseline
‚îÇ   ‚îú‚îÄ‚îÄ train_model_tp2.py           # TP2 - 4 exercices complets
‚îÇ   ‚îú‚îÄ‚îÄ auto_promote.py              # Promotion automatique bas√©e sur seuils
‚îÇ   ‚îú‚îÄ‚îÄ promote_model.py             # Gestion manuelle des stages
‚îÇ   ‚îî‚îÄ‚îÄ evaluate_model.py            # √âvaluation d√©taill√©e des mod√®les
‚îú‚îÄ‚îÄ tests/                           # Tests unitaires
‚îÇ   ‚îî‚îÄ‚îÄ test_model.py                # Tests API et chargement mod√®le
‚îú‚îÄ‚îÄ .github/workflows/               # Pipelines CI/CD
‚îÇ   ‚îú‚îÄ‚îÄ tp2-train-experiments.yml    # Workflow principal (4 exercices)
‚îÇ   ‚îú‚îÄ‚îÄ tp2-quick-test.yml           # Tests rapides sur PR
‚îÇ   ‚îú‚îÄ‚îÄ train-register.yml           # TP1 - Entra√Ænement baseline
‚îÇ   ‚îî‚îÄ‚îÄ deploy.yml                   # D√©ploiement API Flask
‚îú‚îÄ‚îÄ run_tp2.py                       # Script d'ex√©cution local
‚îú‚îÄ‚îÄ Dockerfile                       # Image Docker de production
‚îú‚îÄ‚îÄ requirements.txt                 # D√©pendances Python
‚îî‚îÄ‚îÄ .env.example                     # Template configuration
```

---

## üöÄ Exercices du TP2

### Exercise 1: Bias/Variance Analysis
Diagnostic du mod√®le baseline pour identifier underfitting ou overfitting.
- **Exp√©rience MLflow**: `TP2-Exercise1-BiasVariance`
- **M√©triques**: `train_accuracy`, `val_accuracy`, `accuracy_gap`
- **Tag**: `diagnosis` (HIGH_BIAS, HIGH_VARIANCE, GOOD_FIT)

### Exercise 2: Regularization
Application de L2 regularization et Dropout pour r√©duire l'overfitting.
- **Exp√©rience MLflow**: `TP2-Exercise2-Regularization`
- **Techniques**: L2 (0.001), Dropout (0.2)
- **Comparaison**: Avant/Apr√®s r√©gularisation

### Exercise 3: Optimizer Comparison
Comparaison de 3 optimiseurs sur la m√™me architecture.
- **Exp√©rience MLflow**: `TP2-Exercise3-Optimizers`
- **Optimiseurs**: SGD with Momentum, RMSprop, Adam
- **M√©triques**: `final_test_accuracy`, vitesse de convergence

### Exercise 4: Batch Normalization
Mesure de l'impact de la Batch Normalization sur la stabilit√© et la vitesse.
- **Exp√©rience MLflow**: `TP2-Exercise4-BatchNorm`
- **Comparaison**: Sans vs Avec BatchNorm
- **Architecture**: Dense(512) ‚Üí BatchNorm ‚Üí Dropout ‚Üí Dense(10)

---

## üõ†Ô∏è Installation

### Pr√©requis
- Python 3.10+
- Acc√®s √† un serveur MLflow (distant ou local)
- GitHub repository avec Actions activ√©es

### Installation Locale

```bash
# Cloner le projet
git clone <votre-repo-url>
cd TP2_Deep_Learning

# Cr√©er environnement virtuel
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Installer d√©pendances
pip install -r requirements.txt

# Configurer environnement
cp .env.example .env
# √âditer .env avec vos credentials MLflow
```

---

## üîå Utilisation

### Ex√©cution via GitHub Actions (Recommand√©)

```bash
# 1. Push sur main ‚Üí d√©clenche automatiquement tous les exercices
git add .
git commit -m "feat: run TP2 experiments"
git push origin main

# 2. Ou ex√©cution manuelle depuis GitHub UI
# Actions ‚Üí "TP2 - Run All Experiments" ‚Üí Run workflow
# Choisir: all, exercise1, exercise2, exercise3, ou exercise4
```

**Dur√©e d'ex√©cution**: 25-30 minutes (4 jobs en parall√®le)

### Ex√©cution Locale

```bash
# Tous les exercices
python run_tp2.py

# Exercice sp√©cifique
python -c "from src.train_model_tp2 import exercise_1_baseline; exercise_1_baseline()"
python -c "from src.train_model_tp2 import exercise_2_regularization; exercise_2_regularization()"
python -c "from src.train_model_tp2 import exercise_3_optimizers; exercise_3_optimizers()"
python -c "from src.train_model_tp2 import exercise_4_batch_norm; exercise_4_batch_norm()"
```

---

## ü§ñ Pipeline CI/CD

### 1. TP2 - Run All Experiments (`tp2-train-experiments.yml`)
- **D√©clenchement**: Push sur main/dev, modifications des fichiers TP2, workflow_dispatch
- **4 Jobs Parall√®les**:
  - `exercise1-bias-variance` (7-10 min)
  - `exercise2-regularization` (7-10 min)
  - `exercise3-optimizers` (12-15 min)
  - `exercise4-batchnorm` (10-12 min)
- **Job Summary**: G√©n√®re rapport consolid√© avec tous les r√©sultats
- **Artifacts**: Logs de chaque exercice + rapport markdown

### 2. TP2 - Quick Test (`tp2-quick-test.yml`)
- **D√©clenchement**: Pull Request vers main/dev
- **Dur√©e**: 2-3 minutes
- **Objectif**: Validation rapide (1 epoch, 1000 √©chantillons)

### 3. MLflow Train and Register (`train-register.yml`)
- TP1 - Entra√Ænement baseline avec promotion automatique

### 4. Deploy Application (`deploy.yml`)
- Build Docker + D√©ploiement API Flask sur serveur distant

---

## üìä Visualisation des R√©sultats

### Dans MLflow UI

Acc√©dez √† votre serveur MLflow configur√© dans `.env`:

```bash
# Les exp√©riences cr√©√©es automatiquement:
- TP2-Exercise1-BiasVariance     (1 run)
- TP2-Exercise2-Regularization   (1 run)
- TP2-Exercise3-Optimizers       (3 runs)
- TP2-Exercise4-BatchNorm        (2 runs)
```

**M√©triques track√©es**:
- `train_loss`, `train_accuracy` (par epoch)
- `val_loss`, `val_accuracy` (par epoch)
- `test_loss`, `test_accuracy` (final)
- `loss_gap`, `accuracy_gap` (diagnostic)

**Tags sp√©ciaux**:
- `exercise`: 1, 2, 3, ou 4
- `diagnosis`: HIGH_BIAS, HIGH_VARIANCE, GOOD_FIT
- `optimizer`: SGD_with_momentum, RMSprop, Adam
- `batch_normalization`: true/false

### Dans GitHub Actions

```
Actions ‚Üí TP2 - Run All Experiments ‚Üí Latest run
‚Üí Artifacts: exercise1-logs, exercise2-logs, exercise3-logs, exercise4-logs, tp2-summary-report
‚Üí Summary: R√©sum√© consolid√© avec extraits des logs
```

---

## ‚öôÔ∏è Configuration

### Variables d'Environnement (`.env`)

```bash
# MLflow Tracking
MLFLOW_TRACKING_URI=http://your-mlflow-server:5000
MLFLOW_TRACKING_USERNAME=your_username
MLFLOW_TRACKING_PASSWORD=your_password

# Model Registry
MODEL_NAME=mnist-classifier-tp2

# S3/MinIO (si utilis√©)
MLFLOW_S3_ENDPOINT_URL=https://your-s3-endpoint
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
```

### Secrets GitHub

Configurez dans **Settings ‚Üí Secrets and variables ‚Üí Actions**:

```
MLFLOW_TRACKING_URI
MLFLOW_TRACKING_USERNAME
MLFLOW_TRACKING_PASSWORD
MLFLOW_S3_ENDPOINT_URL
AWS_ACCESS_KEY_ID
AWS_SECRET_ACCESS_KEY
```

---

## üîå API REST (Optionnel)

L'API Flask sert le mod√®le en production pour les pr√©dictions.

### Endpoints

| M√©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/health` | √âtat de sant√© et version du mod√®le |
| GET | `/model/info` | Informations d√©taill√©es sur le mod√®le |
| POST | `/predict` | Pr√©diction sur image (784 pixels) |
| POST | `/model/reload` | Rechargement du mod√®le depuis MLflow |

### Exemple `/predict`

```json
{
  "image": [0, 0, 0.5, 0.8, ..., 0]
}
```

### Lancement Local

```bash
python -m src.app
# API accessible sur http://localhost:5000
```

### D√©ploiement Docker

```bash
docker build -t mnist-mlflow-tp2-app .
docker run -p 5000:5000 --env-file .env mnist-mlflow-tp2-app
```

---

## üß™ Tests

```bash
# Ex√©cuter tous les tests
pytest tests/test_model.py

# Avec couverture
pytest --cov=src tests/
```

---

## üìà R√©sultats Attendus

### Exercise 1: Bias/Variance
```
Train Accuracy: 0.9856
Val Accuracy: 0.9778
Accuracy Gap: 0.0078
DIAGNOSIS: GOOD_FIT
```

### Exercise 2: Regularization
```
Sans r√©gularisation ‚Üí Gap: 0.0078
Avec r√©gularisation ‚Üí Gap: 0.0022 ‚úì Am√©lioration
```

### Exercise 3: Optimizers
```
SGD_with_momentum : 0.9756
RMSprop          : 0.9801
Adam             : 0.9823 ‚úì Meilleur
```

### Exercise 4: Batch Normalization
```
Sans BatchNorm : 0.9778
Avec BatchNorm : 0.9812 ‚úì Plus rapide + stable
```

---

## üìö Documentation
- [TensorFlow Documentation](https://www.tensorflow.org/api_docs)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [GitHub Actions Documentation](https://docs.github.com/en/actions)

---

## üë• Auteurs

**ENSPY - Universit√© de Yaound√© I**  
FOMEKONG TAMDJI JONATHAN BACHELARD 21P021 - D√©partement de G√©nie Informatique - Promotion 5GI 2025

**Instructeurs**:
- Louis Fippo Fitime - louis.fippo@univ-yaounde1.cm
---

## ‚öñÔ∏è Licence

Distribu√© sous la licence MIT. Voir [LICENSE](LICENSE) pour plus d'informations.